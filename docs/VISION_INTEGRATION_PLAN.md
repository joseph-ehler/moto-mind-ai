# ğŸ” Vision System Integration with Guided Capture

## ğŸ¯ Objective
Integrate your existing vision/OCR system into the Guided Capture Flow to automatically extract fuel data from photos, then let users review/edit before saving.

---

## ğŸ“Š Current Flow vs. New Flow

### Current Flow:
1. User captures 4 photos âœ…
2. Click "Save All" â†’ Immediate save âœ…
3. Event created with NO fuel data âŒ
4. User must manually edit event later âŒ

### New Flow with Vision:
1. User captures 4 photos âœ…
2. Click "Save All" â†’ Vision Processing Step (NEW)
3. API calls to `/api/vision/process` for each photo:
   - **Receipt** â†’ Extract: `total_amount`, `gallons`, `price_per_gallon`, `station_name`, `date`
   - **Odometer** â†’ Extract: `miles`
   - **Gauge** â†’ Extract: `fuel_level` (optional)
   - **Additives** â†’ Extract: `products` (optional)
4. Aggregate extracted data from all photos
5. Show `<DataConfirmation>` modal with pre-filled form
6. User reviews/edits the auto-extracted data
7. Click "Save Data" â†’ Complete save (event + photos + extracted data)
8. Navigate to event page with ALL data populated âœ…

---

## ğŸ”§ Technical Implementation

### Step 1: Add New State Variables

**File:** `components/capture/GuidedCaptureFlow.tsx`

```tsx
// Add these new state variables after line 73:
const [isProcessingVision, setIsProcessingVision] = useState(false)
const [extractedData, setExtractedData] = useState<any>(null)
const [showDataConfirmation, setShowDataConfirmation] = useState(false)
const [visionProgress, setVisionProgress] = useState({
  current: 0,
  total: 0,
  currentPhoto: ''
})
```

---

### Step 2: Create Vision Processing Function

**File:** `components/capture/GuidedCaptureFlow.tsx`

```tsx
const processPhotosWithVision = async (photos: CapturedPhoto[]) => {
  setIsProcessingVision(true)
  const results: any[] = []
  
  try {
    // Map photo steps to document types
    const stepToDocType = {
      'receipt': 'fuel_receipt',
      'odometer': 'odometer',
      'gauge': 'fuel_gauge',
      'additives': 'product_label'
    }
    
    // Process each photo through vision API
    for (let i = 0; i < photos.length; i++) {
      const photo = photos[i]
      setVisionProgress({
        current: i + 1,
        total: photos.length,
        currentPhoto: photo.stepId
      })
      
      console.log(`ğŸ” Processing ${photo.stepId} with vision...`)
      
      // Convert photo to FormData
      const formData = new FormData()
      formData.append('image', photo.file)
      formData.append('mode', 'extract')
      formData.append('document_type', stepToDocType[photo.stepId] || 'fuel_receipt')
      formData.append('vehicle_id', vehicleId)
      
      // Call vision API
      const response = await fetch('/api/vision/process', {
        method: 'POST',
        body: formData
      })
      
      if (response.ok) {
        const visionResult = await response.json()
        results.push({
          stepId: photo.stepId,
          data: visionResult.data,
          confidence: visionResult.confidence
        })
        console.log(`âœ… Vision extracted from ${photo.stepId}:`, visionResult.data)
      } else {
        console.warn(`âš ï¸ Vision failed for ${photo.stepId}, will use manual entry`)
        results.push({
          stepId: photo.stepId,
          data: null,
          confidence: 0
        })
      }
    }
    
    // Aggregate data from all photos
    const aggregated = aggregateExtractedData(results)
    setExtractedData(aggregated)
    setShowDataConfirmation(true)
    
  } catch (error) {
    console.error('âŒ Vision processing error:', error)
    alert('Vision processing failed. You can still enter data manually.')
    // Show confirmation with empty data
    setExtractedData({})
    setShowDataConfirmation(true)
  } finally {
    setIsProcessingVision(false)
  }
}
```

---

### Step 3: Create Data Aggregation Function

**File:** `components/capture/GuidedCaptureFlow.tsx`

```tsx
const aggregateExtractedData = (results: any[]) => {
  // Initialize with defaults
  const aggregated: any = {
    gallons: null,
    price_total: null,
    unit_price: null,
    date: new Date().toISOString().split('T')[0],
    station: null,
    miles: null,
    ocr_confidence: 0
  }
  
  // Extract data from each photo type
  for (const result of results) {
    if (!result.data) continue
    
    switch (result.stepId) {
      case 'receipt':
        // Receipt has most of the fuel data
        aggregated.gallons = result.data.gallons || aggregated.gallons
        aggregated.price_total = result.data.total_amount || result.data.price_total || aggregated.price_total
        aggregated.unit_price = result.data.price_per_gallon || result.data.unit_price || aggregated.unit_price
        aggregated.station = result.data.station_name || result.data.station || aggregated.station
        aggregated.date = result.data.date || aggregated.date
        aggregated.ocr_confidence = Math.max(aggregated.ocr_confidence, result.confidence || 0)
        break
        
      case 'odometer':
        // Odometer reading
        aggregated.miles = result.data.miles || result.data.odometer_reading || aggregated.miles
        break
        
      case 'gauge':
        // Optional: Fuel level
        aggregated.fuel_level = result.data.fuel_level || result.data.percentage
        break
        
      case 'additives':
        // Optional: Products used
        aggregated.products = result.data.products || []
        break
    }
  }
  
  // Calculate unit_price if not extracted but have total and gallons
  if (!aggregated.unit_price && aggregated.price_total && aggregated.gallons) {
    aggregated.unit_price = (aggregated.price_total / aggregated.gallons).toFixed(3)
  }
  
  console.log('ğŸ“Š Aggregated data from vision:', aggregated)
  return aggregated
}
```

---

### Step 4: Modify handleSave to Call Vision First

**File:** `components/capture/GuidedCaptureFlow.tsx`

```tsx
// REPLACE the existing handleSave function (around line 283)
const handleSave = async () => {
  if (!hasRequiredPhotos) {
    alert('Please complete all required steps before saving.')
    return
  }
  
  if (!session?.user?.tenant_id) {
    alert('Authentication error. Please sign in again.')
    router.push('/auth/signin')
    return
  }
  
  // NEW: First process photos with vision, then show confirmation
  await processPhotosWithVision(capturedPhotos)
  
  // The actual save happens after user confirms data in DataConfirmation modal
}
```

---

### Step 5: Add Data Confirmation Handler

**File:** `components/capture/GuidedCaptureFlow.tsx`

```tsx
const handleDataConfirmed = async (confirmedData: any) => {
  const tenantId = session.user.tenant_id
  setIsSaving(true)
  setShowDataConfirmation(false)
  
  try {
    // 1. Process photos (compression, HEIC conversion)
    console.log('ğŸ”„ Processing photos...')
    const result = await bulkProcessPhotos(capturedPhotos.map(p => p.file), {
      onProgress: (index, progress) => {
        setBulkProcessing(prev => prev ? {
          ...prev,
          photos: prev.photos.map((p, i) => 
            i === index ? { ...p, progress, status: 'processing' } : p
          )
        } : null)
      }
    })
    
    console.log('âœ… Bulk processing complete:', result)
    
    // 2. Create event with extracted data
    const { data: event, error: eventError } = await supabase
      .from('vehicle_events')
      .insert({
        vehicle_id: vehicleId,
        tenant_id: tenantId,
        type: eventType,
        date: confirmedData.date,
        // Add extracted fuel data
        total_amount: confirmedData.price_total,
        gallons: confirmedData.gallons,
        miles: confirmedData.miles,
        vendor: confirmedData.station,
        // Mark as vision-extracted
        ocr_confidence: confirmedData.ocr_confidence,
        is_manual_entry: false
      })
      .select()
      .single()
    
    if (eventError) throw new Error(`Event creation failed: ${eventError.message}`)
    console.log('âœ… Event created with data:', event.id)
    
    // 3-7. Continue with existing photo upload, metadata, linking logic
    // (Keep the existing code from line 367 onwards)
    
  } catch (error) {
    console.error('âŒ Save failed:', error)
    alert(`Failed to save event: ${error instanceof Error ? error.message : 'Unknown error'}`)
  } finally {
    setIsSaving(false)
    setBulkProcessing(null)
  }
}
```

---

### Step 6: Update UI to Show Vision Processing

**File:** `components/capture/GuidedCaptureFlow.tsx`

Add this in the JSX (around line 750, before the save button):

```tsx
{/* Vision Processing Modal */}
{isProcessingVision && (
  <div className="fixed inset-0 bg-black/50 flex items-center justify-center z-50">
    <Card className="max-w-md w-full mx-4">
      <Stack spacing="md">
        <Heading level="subsection">ğŸ” Extracting Data from Photos...</Heading>
        <Text>
          AI is reading your photos to extract fuel data.
          Processing {visionProgress.currentPhoto}...
        </Text>
        <div className="w-full bg-gray-200 rounded-full h-2">
          <div 
            className="bg-blue-600 h-2 rounded-full transition-all"
            style={{ width: `${(visionProgress.current / visionProgress.total) * 100}%` }}
          />
        </div>
        <Text size="sm" className="text-gray-600">
          {visionProgress.current} of {visionProgress.total} photos processed
        </Text>
      </Stack>
    </Card>
  </div>
)}

{/* Data Confirmation Modal */}
{showDataConfirmation && extractedData && (
  <DataConfirmation
    kind="fuel_purchase"
    extractedData={extractedData}
    vehicleId={vehicleId}
    onConfirm={handleDataConfirmed}
    onCancel={() => {
      setShowDataConfirmation(false)
      setIsSaving(false)
    }}
  />
)}
```

---

## ğŸ“¦ Required Imports

Add these to the top of `GuidedCaptureFlow.tsx`:

```tsx
import { DataConfirmation } from './DataConfirmation'
import { Card } from '@/components/design-system'
```

---

## ğŸ§ª Testing Checklist

1. **Capture 4 photos** (receipt, odometer, gauge, additives)
2. **Click "Save All"**
3. **Verify vision processing modal appears** with progress
4. **Check console logs** for vision extraction results
5. **Verify DataConfirmation modal appears** with pre-filled data
6. **Edit any fields** if needed
7. **Click "Save Data"**
8. **Verify event is created** with all extracted data
9. **Verify 4 photos are uploaded** and linked
10. **Navigate to event page** and see populated fields

---

## ğŸ¯ Expected Results

**Console Output:**
```
âœ… Authenticated user with tenant: [tenant-id]
âœ… Session created: [session-id]
âœ… Session updated: 4/4 photos
ğŸ” Processing receipt with vision...
âœ… Vision extracted from receipt: { total_amount: 45.32, gallons: 12.5, ... }
ğŸ” Processing odometer with vision...
âœ… Vision extracted from odometer: { miles: 45234 }
ğŸ” Processing gauge with vision...
ğŸ” Processing additives with vision...
ğŸ“Š Aggregated data from vision: { price_total: 45.32, gallons: 12.5, miles: 45234, ... }
[User reviews and confirms data]
âœ… Event created with data: [event-id]
âœ… Uploaded 4/4 photos
âœ… Session completed
ğŸ‰ All done! Saved 4 photos
```

**Event Page:**
- âœ… Total Cost: $45.32 (from receipt)
- âœ… Gallons: 12.5 (from receipt)
- âœ… Price/Gallon: $3.63 (calculated)
- âœ… Station: Shell (from receipt)
- âœ… Odometer: 45,234 mi (from odometer photo)
- âœ… 4 photos displayed

---

## ğŸš€ Benefits

1. **90% faster data entry** - Auto-fill from photos
2. **Higher accuracy** - OCR extracts exact values
3. **Better UX** - Review/edit instead of manual typing
4. **Complete events** - No more empty fields
5. **Audit trail** - OCR confidence scores tracked
6. **Flexible** - Users can still edit if OCR misreads

---

## âš ï¸ Error Handling

**If vision API fails:**
- Show DataConfirmation with empty fields
- User manually enters data
- System still saves event normally

**If user cancels confirmation:**
- Return to gallery view
- Keep captured photos
- Don't save event yet

---

**Ready to implement? Shall I proceed with these changes?** ğŸš€
